{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "id3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxjN3lblFXkjWL7iGb3Qc/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadikul1500/Deciosion_tree/blob/main/id3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2TuamCWsSG0"
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from random import shuffle\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnzWSVwItRNq",
        "outputId": "6f4998f4-35cf-4c13-939c-05168c044acf",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad6df2d3-7a94-45dd-8712-64e0038145d9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad6df2d3-7a94-45dd-8712-64e0038145d9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving parkinsons.csv to parkinsons (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElPIkmsGpBZ4"
      },
      "source": [
        "def split_dataset(data, start, end):\n",
        "  #size = round((1/size)*len(data))\n",
        "\n",
        "  test_indices = [i for i in range(start, end)]\n",
        "  #test_indices = random.sample(indices, size)\n",
        "\n",
        "  test = data.loc[test_indices]\n",
        "  train = data.drop(test_indices)\n",
        "\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaZWXcjkywkt"
      },
      "source": [
        "#print([i for i in range(start, end)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFUfo7Gxuqdb"
      },
      "source": [
        "def isPure(data):\n",
        "  labels = data[:, -1]\n",
        "  output_classes = np.unique(labels)\n",
        "  \n",
        "  return len(output_classes) == 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1pmiTLqvt9_"
      },
      "source": [
        "def classify_data(data):\n",
        "  labels = data[:, -1]\n",
        "  output_classes, count_output_classes = np.unique(labels, return_counts=True)\n",
        "\n",
        "  return output_classes[count_output_classes.argmax()]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR93a_Y0GMq0"
      },
      "source": [
        "def split_data(data, column, value):\n",
        "  rows = data[:, column]\n",
        "  feature_type = FEATURE_TYPES[column]\n",
        "\n",
        "  if feature_type == \"continuous\":\n",
        "    return data[rows < value], data[rows >= value]\n",
        "  else:\n",
        "    return data[rows == value], data[rows != value]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl2T9GqLNoPg"
      },
      "source": [
        "def get_entropy(data):\n",
        "  _, unique_vlaue_counts = np.unique(data[:, -1], return_counts=True)\n",
        "\n",
        "  probabilities = unique_vlaue_counts / unique_vlaue_counts.sum()\n",
        "\n",
        "  return -1 * sum(probabilities*np.log2(probabilities))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ04dHAeQfub"
      },
      "source": [
        "def get_overall_entropy(data_below, data_upper):\n",
        "  total_size = len(data_below) + len(data_upper)\n",
        "\n",
        "  return ((len(data_below) / total_size) * get_entropy(data_below)) + ((len(data_upper) / total_size) * get_entropy(data_upper))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzt3Z_1cTf-8"
      },
      "source": [
        "def determine_best_split(data, potential_splits):\n",
        "  overall_entropy = 1e9\n",
        "  for  key in potential_splits.keys():\n",
        "    for value in potential_splits[key]:\n",
        "      data_below, data_upper = split_data(data, key, value)\n",
        "      current_entropy = get_overall_entropy(data_below, data_upper)\n",
        "\n",
        "      if current_entropy < overall_entropy:\n",
        "        overall_entropy = current_entropy\n",
        "        best_split_column = key\n",
        "        best_split_value = value\n",
        "  \n",
        "  return best_split_column, best_split_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuKg6o_xc04Q"
      },
      "source": [
        "def get_potential_split(data):\n",
        "  potential_splits = {}\n",
        "  _, n_column = data.shape\n",
        "\n",
        "  for col in range(n_column-1):\n",
        "    #print(data[:, col])    \n",
        "    unique_values = np.unique(data[:, col])\n",
        "    \n",
        "    if FEATURE_TYPES[col] == \"continuous\":\n",
        "      potential_splits[col] = []\n",
        "      for index in range(1, len(unique_values)):\n",
        "        potential_splits[col] += [(unique_values[index] + unique_values[index-1]) / 2]\n",
        "  \n",
        "    elif len(unique_values) > 1:\n",
        "      potential_splits[col] = unique_values\n",
        "  \n",
        "  return potential_splits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1m3uqigIWVy"
      },
      "source": [
        "def decision_tree_algorithm(data, column_heading, counter=0, min_point=2, max_depth=6):\n",
        "  \n",
        "  if isPure(data) or len(data) < 2 or counter > max_depth:\n",
        "    return classify_data(data)\n",
        "\n",
        "  else:\n",
        "    #counter += 1\n",
        "    potential_splits = get_potential_split(data)\n",
        "    #print(potential_splits)\n",
        "    if potential_splits:\n",
        "      split_column, split_value = determine_best_split(data, potential_splits)\n",
        "      data_below, data_upper = split_data(data, split_column, split_value)\n",
        "    else:\n",
        "      return classify_data(data)\n",
        "      \n",
        "    if FEATURE_TYPES[split_column] == \"continuous\":\n",
        "      question = \"{} < {}\".format(column_heading[split_column], split_value)\n",
        "    else:\n",
        "      question = \"{} = {}\".format(column_heading[split_column], split_value)\n",
        "    subtree = {question:[]}\n",
        "\n",
        "    yes_answer = decision_tree_algorithm(data_below, column_heading, counter+1, min_point, max_depth)\n",
        "    no_answer = decision_tree_algorithm(data_upper, column_heading, counter+1, min_point, max_depth)\n",
        "\n",
        "    subtree[question].append(yes_answer)\n",
        "    subtree[question].append(no_answer)\n",
        "\n",
        "    return subtree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuEAN3Px0Brf",
        "outputId": "d7c8eb61-dc68-47de-fc50-345984c04539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#print(get_overall_entropy(split_data(train.values, 3, .8)))\n",
        "print(np.unique(['a','b','a','d','e','c','e',5, 7]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['5' '7' 'a' 'b' 'c' 'd' 'e']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYOQcf6Msyot"
      },
      "source": [
        "#print(test.iloc[2][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjh-HeLJ8eSg"
      },
      "source": [
        "def classify_test_data(data, tree):\n",
        "  question = list(tree.keys())[0]\n",
        "  feature, compare, value = question.split()\n",
        "\n",
        "  if compare == \"<\":\n",
        "    if data[feature] < float(value):\n",
        "      answer = tree[question][0]\n",
        "    else:\n",
        "      answer = tree[question][1]\n",
        "  \n",
        "  else:\n",
        "    if str(data[feature]) == value:\n",
        "      answer = tree[question][0]\n",
        "    else:\n",
        "      answer = tree[question][1]\n",
        "\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    return classify_test_data(data, answer)  \n",
        "\n",
        "#data = test.iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtT3NoHcGKcO"
      },
      "source": [
        "def get_accuracy(test, tree):\n",
        "  count = 0\n",
        "  total = len(test)\n",
        "\n",
        "  print('******************** testing ************************\\n')\n",
        "  for i in range(total):\n",
        "    row = test.iloc[i]\n",
        "    answer = classify_test_data(row, tree)\n",
        "\n",
        "    if answer == row[-1]:\n",
        "      count += 1\n",
        "      print(row[-1], answer)\n",
        "    else: print(row[-1], answer, \" WRONG_AMSWER_DETECTED\")\n",
        "  return count / total "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vVWi2GzOnTY"
      },
      "source": [
        "FEATURE_TYPES = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icy8ApvtyuG7"
      },
      "source": [
        "def get_type_of_feature(df):\n",
        "  feature_types = []\n",
        "  unique_value_threshold = 15\n",
        "\n",
        "  for col  in df.columns:\n",
        "    val = df[col].unique()[0]\n",
        "\n",
        "    if isinstance(val, str) or len(df[col].unique()) < unique_value_threshold:\n",
        "      feature_types.append(\"categorical\")\n",
        "    else:\n",
        "      feature_types.append(\"continuous\")\n",
        "  return feature_types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aywr8CQStNip"
      },
      "source": [
        "for f in uploaded.keys():\n",
        "  csv_file = pd.read_csv(f)\n",
        "  csv_file = csv_file.rename(columns={list(csv_file.columns)[-1] : \"label\"})\n",
        "  column_heading = csv_file.columns\n",
        "  print(csv_file.info())\n",
        "  \n",
        "  global FEATURE_TYPES\n",
        "  FEATURE_TYPES = get_type_of_feature(csv_file)\n",
        "  i = 0\n",
        "  for column in csv_file.columns:\n",
        "    print(column, FEATURE_TYPES[i])\n",
        "    i += 1\n",
        "\n",
        "  #shuffle dataset\n",
        "  csv_file = csv_file.sample(frac = 1)\n",
        "\n",
        "  numberOfFold = int(input(\"number of fold: \"))\n",
        "  percent = int(len(csv_file) / numberOfFold)\n",
        "\n",
        "  accuracy = []\n",
        "\n",
        "  for t in range(numberOfFold):\n",
        "    start = t * percent\n",
        "    end = start + percent\n",
        "    #print(start, end)\n",
        "    train, test = split_dataset(csv_file, start, end )\n",
        "\n",
        "    #potential_splits = get_potential_split(train.values)\n",
        "    tree = decision_tree_algorithm(train.values, column_heading, max_depth=10)\n",
        "    #print(tree)\n",
        "    print('\\n############ Tree ##########\\n')\n",
        "    pprint(tree)\n",
        "    print('\\n')\n",
        "    accuracy += [get_accuracy(test, tree)]\n",
        "    print(\"***********accuracy: \", accuracy[-1])\n",
        "\n",
        "\n",
        "    #print(test)\n",
        "    #print(isPure(train.values))\n",
        "    #csv_file = csv_file.drop()\n",
        "  print(\"**********mean accuracy: \", sum(accuracy)/ numberOfFold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgubT9f5ptwS",
        "outputId": "58d02843-4f3a-4931-cacb-e48724c0ce30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(csv_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3krZaQUyjD4i",
        "outputId": "9f71489a-8b62-4fc9-a2be-493dc2bf60a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "'''\n",
        "  heading = list(csv_file.columns)\n",
        "\n",
        "  data = csv_file.values.tolist()\n",
        "\n",
        "  shuffle(data)\n",
        "  shuffledData = list.copy(data)\n",
        "\n",
        "  numberOfFold = int(input(\"number of fold: \"))\n",
        "  percent = int(len(shuffledData) / numberOfFold)\n",
        "\n",
        "  accuracy = []\n",
        "\n",
        "  for i in range(numberOfFold):\n",
        "    start = i * percent\n",
        "    end = start + percent\n",
        "    \n",
        "    test = np.array(shuffledData[start : end])\n",
        "    train = np.array(shuffledData[: start] + shuffledData[end-1:])\n",
        "\n",
        "    #test_df = np.asarray(test)\n",
        "    #train_df = np.asarray(train)\n",
        "\n",
        "    #print(type(test))\n",
        "    #print(start, end)\n",
        "    print(train)\n",
        "    #tree = build_tr#ee(train, heading)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  heading = list(csv_file.columns)\\n\\n  data = csv_file.values.tolist()\\n\\n  shuffle(data)\\n  shuffledData = list.copy(data)\\n\\n  numberOfFold = int(input(\"number of fold: \"))\\n  percent = int(len(shuffledData) / numberOfFold)\\n\\n  accuracy = []\\n\\n  for i in range(numberOfFold):\\n    start = i * percent\\n    end = start + percent\\n    \\n    test = np.array(shuffledData[start : end])\\n    train = np.array(shuffledData[: start] + shuffledData[end-1:])\\n\\n    #test_df = np.asarray(test)\\n    #train_df = np.asarray(train)\\n\\n    #print(type(test))\\n    #print(start, end)\\n    print(train)\\n    #tree = build_tr#ee(train, heading)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6JzkYJtsnSh",
        "outputId": "e19a9351-14cd-43f3-ae07-3bf0b015b38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "'''\n",
        "def information_gain(left, right, parent_entropy):\n",
        "  probability = len(right) * 1.0 / (len(right) + len(left))\n",
        "  return parent_entropy - probability * entropy(left) - (1-probability) * entropy(right)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef information_gain(left, right, parent_entropy):\\n  probability = len(right) * 1.0 / (len(right) + len(left))\\n  return parent_entropy - probability * entropy(left) - (1-probability) * entropy(right)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97xt-JGBj7pl",
        "outputId": "a6d03a27-0c20-4e14-a5e7-c2cbedf93fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "'''\n",
        "for f in uploaded.keys():\n",
        "  df = pd.read_csv(f)\n",
        "  df[\"label\"] = df.Survived\n",
        "  df = df.drop([\"PassengerId\", \"Name\", \"Survived\", \"Ticket\", \"Cabin\"], axis=1)\n",
        " \n",
        "  df = df.fillna({\"Age\":df.Age.median(), \"Embarked\": df.Embarked.mode()[0]})\n",
        "  column_heading = df.columns\n",
        "  #print(df.head())\n",
        "  print(df.info()) \n",
        "\n",
        "  global FEATURE_TYPES\n",
        "  FEATURE_TYPES = get_type_of_feature(df)\n",
        "  i = 0\n",
        "  for column in df.columns:\n",
        "    print(column, FEATURE_TYPES[i])\n",
        "    i += 1\n",
        "  train, test = split_dataset(df, 5)\n",
        "  tree = decision_tree_algorithm(train.values, column_heading, max_depth=10)\n",
        "  #print(tree)\n",
        "  #print()\n",
        "  pprint(tree, width=50)\n",
        "  print('\\n')\n",
        "  print(get_accuracy(test, tree))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor f in uploaded.keys():\\n  df = pd.read_csv(f)\\n  df[\"label\"] = df.Survived\\n  df = df.drop([\"PassengerId\", \"Name\", \"Survived\", \"Ticket\", \"Cabin\"], axis=1)\\n \\n  df = df.fillna({\"Age\":df.Age.median(), \"Embarked\": df.Embarked.mode()[0]})\\n  column_heading = df.columns\\n  #print(df.head())\\n  print(df.info()) \\n\\n  global FEATURE_TYPES\\n  FEATURE_TYPES = get_type_of_feature(df)\\n  i = 0\\n  for column in df.columns:\\n    print(column, FEATURE_TYPES[i])\\n    i += 1\\n  train, test = split_dataset(df, 5)\\n  tree = decision_tree_algorithm(train.values, column_heading, max_depth=10)\\n  #print(tree)\\n  #print()\\n  pprint(tree, width=50)\\n  print(\\'\\n\\')\\n  print(get_accuracy(test, tree))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}